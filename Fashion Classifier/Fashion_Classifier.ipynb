{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b05487-d904-4c7b-8521-a214ba628833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.optim  as optim\n",
    "import matplotlib.pyplot as plt\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf2b0c5-6634-4200-a69b-465a41b87e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 9')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSet=pd.read_csv(r\"D:\\Datasets\\MNIST Fashion\\fashion-mnist_train.csv\")\n",
    "testSet=pd.read_csv(r\"D:\\Datasets\\MNIST Fashion\\fashion-mnist_test.csv\")\n",
    "image_data = trainSet.iloc[1, 1:].values  # Pixel values\n",
    "image_label = trainSet.iloc[1, 0]         # Label\n",
    "\n",
    "# Reshape the image data into 28x28 pixels\n",
    "image_data = image_data.reshape(28, 28)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_data, cmap='gray')\n",
    "plt.title(f'Label: {image_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f8e752-02b0-4059-9f79-e51d9cbe6b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "           ..\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking null values\n",
    "print(trainSet.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccd668b-636f-4662-8f4c-d61b09621664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataframe\n",
    "print(torch.cuda.is_available())\n",
    "print(device)\n",
    "train_x,train_y=torch.from_numpy(np.array(trainSet.iloc[:,1:])),torch.from_numpy(np.array(trainSet.iloc[:,0]))\n",
    "train_x=train_x.to(device)\n",
    "train_y=train_y.to(device)\n",
    "test_x,test_y=torch.from_numpy(np.array(testSet.iloc[:,1:])),torch.from_numpy(np.array(testSet.iloc[:,0]))\n",
    "test_x=test_x.to(device)\n",
    "test_y=test_y.to(device)\n",
    "\n",
    "#Standarizing the pixels\n",
    "train_x,test_x=train_x/255.0,test_x/255.0\n",
    "\n",
    "#One hot  encoding the labels\n",
    "train_y=torch.eye(10,device=device)[train_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9af861e-cc2f-4a94-b0b8-bb031ba8883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual model code\n",
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self,lr,epochs,neurons):\n",
    "        super().__init__()\n",
    "        self.lr=lr\n",
    "        self.epochs=epochs\n",
    "        self.neuron_no=neurons\n",
    "        self.l1=nn.Linear(784,self.neuron_no,device=device)\n",
    "        self.l2=nn.Linear(self.neuron_no,self.neuron_no,device=device)\n",
    "        self.l3=nn.Linear(self.neuron_no,10,device=device)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.optimizer=optim.SGD(params=self.parameters(),momentum=0.9,lr=self.lr)\n",
    "        nn.init.kaiming_uniform_(self.l1.weight,nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.l2.weight,nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.l3.weight,nonlinearity='relu')\n",
    "        \n",
    "\n",
    "    def forward(self,x:torch.Tensor)->torch.Tensor:\n",
    "        x=self.relu(self.l1(x))\n",
    "        x=self.relu(self.l2(x))\n",
    "        return self.l3(x)\n",
    "\n",
    "    def fit(self,x:torch.Tensor,y:torch.Tensor)->None:\n",
    "        self.train()\n",
    "        loss_fn=nn.CrossEntropyLoss()\n",
    "        for i in range(self.epochs):\n",
    "            print(f\"Iteration {i}\")\n",
    "            y_pred=self.forward(x)\n",
    "            loss=loss_fn(y_pred,y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                if i%10==0:\n",
    "                    print(f\"Loss={loss}\")\n",
    "            self.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31bc7a7-6148-4a75-920f-c4f8949bd123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Loss=2.423002004623413\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Loss=0.9643917679786682\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Loss=1.0783417224884033\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Loss=0.7853319644927979\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Loss=0.6397980451583862\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Loss=0.5777662992477417\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Loss=0.5388683080673218\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 70\n",
      "Loss=0.5068110823631287\n",
      "Iteration 71\n",
      "Iteration 72\n",
      "Iteration 73\n",
      "Iteration 74\n",
      "Iteration 75\n",
      "Iteration 76\n",
      "Iteration 77\n",
      "Iteration 78\n",
      "Iteration 79\n",
      "Iteration 80\n",
      "Loss=0.4837389588356018\n",
      "Iteration 81\n",
      "Iteration 82\n",
      "Iteration 83\n",
      "Iteration 84\n",
      "Iteration 85\n",
      "Iteration 86\n",
      "Iteration 87\n",
      "Iteration 88\n",
      "Iteration 89\n",
      "Iteration 90\n",
      "Loss=0.4648532569408417\n",
      "Iteration 91\n",
      "Iteration 92\n",
      "Iteration 93\n",
      "Iteration 94\n",
      "Iteration 95\n",
      "Iteration 96\n",
      "Iteration 97\n",
      "Iteration 98\n",
      "Iteration 99\n",
      "Iteration 100\n",
      "Loss=0.4491991698741913\n",
      "Iteration 101\n",
      "Iteration 102\n",
      "Iteration 103\n",
      "Iteration 104\n",
      "Iteration 105\n",
      "Iteration 106\n",
      "Iteration 107\n",
      "Iteration 108\n",
      "Iteration 109\n",
      "Iteration 110\n",
      "Loss=0.4356243312358856\n",
      "Iteration 111\n",
      "Iteration 112\n",
      "Iteration 113\n",
      "Iteration 114\n",
      "Iteration 115\n",
      "Iteration 116\n",
      "Iteration 117\n",
      "Iteration 118\n",
      "Iteration 119\n",
      "Iteration 120\n",
      "Loss=0.4238485097885132\n",
      "Iteration 121\n",
      "Iteration 122\n",
      "Iteration 123\n",
      "Iteration 124\n",
      "Iteration 125\n",
      "Iteration 126\n",
      "Iteration 127\n",
      "Iteration 128\n",
      "Iteration 129\n",
      "Iteration 130\n",
      "Loss=0.41363170742988586\n",
      "Iteration 131\n",
      "Iteration 132\n",
      "Iteration 133\n",
      "Iteration 134\n",
      "Iteration 135\n",
      "Iteration 136\n",
      "Iteration 137\n",
      "Iteration 138\n",
      "Iteration 139\n",
      "Iteration 140\n",
      "Loss=0.40470781922340393\n",
      "Iteration 141\n",
      "Iteration 142\n",
      "Iteration 143\n",
      "Iteration 144\n",
      "Iteration 145\n",
      "Iteration 146\n",
      "Iteration 147\n",
      "Iteration 148\n",
      "Iteration 149\n",
      "Iteration 150\n",
      "Loss=0.39683178067207336\n",
      "Iteration 151\n",
      "Iteration 152\n",
      "Iteration 153\n",
      "Iteration 154\n",
      "Iteration 155\n",
      "Iteration 156\n",
      "Iteration 157\n",
      "Iteration 158\n",
      "Iteration 159\n",
      "Iteration 160\n",
      "Loss=0.38989102840423584\n",
      "Iteration 161\n",
      "Iteration 162\n",
      "Iteration 163\n",
      "Iteration 164\n",
      "Iteration 165\n",
      "Iteration 166\n",
      "Iteration 167\n",
      "Iteration 168\n",
      "Iteration 169\n",
      "Iteration 170\n",
      "Loss=0.38369089365005493\n",
      "Iteration 171\n",
      "Iteration 172\n",
      "Iteration 173\n",
      "Iteration 174\n",
      "Iteration 175\n",
      "Iteration 176\n",
      "Iteration 177\n",
      "Iteration 178\n",
      "Iteration 179\n",
      "Iteration 180\n",
      "Loss=0.37802982330322266\n",
      "Iteration 181\n",
      "Iteration 182\n",
      "Iteration 183\n",
      "Iteration 184\n",
      "Iteration 185\n",
      "Iteration 186\n",
      "Iteration 187\n",
      "Iteration 188\n",
      "Iteration 189\n",
      "Iteration 190\n",
      "Loss=0.372832328081131\n",
      "Iteration 191\n",
      "Iteration 192\n",
      "Iteration 193\n",
      "Iteration 194\n",
      "Iteration 195\n",
      "Iteration 196\n",
      "Iteration 197\n",
      "Iteration 198\n",
      "Iteration 199\n",
      "Iteration 200\n",
      "Loss=0.36807259917259216\n",
      "Iteration 201\n",
      "Iteration 202\n",
      "Iteration 203\n",
      "Iteration 204\n",
      "Iteration 205\n",
      "Iteration 206\n",
      "Iteration 207\n",
      "Iteration 208\n",
      "Iteration 209\n",
      "Iteration 210\n",
      "Loss=0.36369073390960693\n",
      "Iteration 211\n",
      "Iteration 212\n",
      "Iteration 213\n",
      "Iteration 214\n",
      "Iteration 215\n",
      "Iteration 216\n",
      "Iteration 217\n",
      "Iteration 218\n",
      "Iteration 219\n",
      "Iteration 220\n",
      "Loss=0.35961970686912537\n",
      "Iteration 221\n",
      "Iteration 222\n",
      "Iteration 223\n",
      "Iteration 224\n",
      "Iteration 225\n",
      "Iteration 226\n",
      "Iteration 227\n",
      "Iteration 228\n",
      "Iteration 229\n",
      "Iteration 230\n",
      "Loss=0.35577407479286194\n",
      "Iteration 231\n",
      "Iteration 232\n",
      "Iteration 233\n",
      "Iteration 234\n",
      "Iteration 235\n",
      "Iteration 236\n",
      "Iteration 237\n",
      "Iteration 238\n",
      "Iteration 239\n",
      "Iteration 240\n",
      "Loss=0.3529517650604248\n",
      "Iteration 241\n",
      "Iteration 242\n",
      "Iteration 243\n",
      "Iteration 244\n",
      "Iteration 245\n",
      "Iteration 246\n",
      "Iteration 247\n",
      "Iteration 248\n",
      "Iteration 249\n",
      "Iteration 250\n",
      "Loss=0.3489192724227905\n",
      "Iteration 251\n",
      "Iteration 252\n",
      "Iteration 253\n",
      "Iteration 254\n",
      "Iteration 255\n",
      "Iteration 256\n",
      "Iteration 257\n",
      "Iteration 258\n",
      "Iteration 259\n",
      "Iteration 260\n",
      "Loss=0.34581923484802246\n",
      "Iteration 261\n",
      "Iteration 262\n",
      "Iteration 263\n",
      "Iteration 264\n",
      "Iteration 265\n",
      "Iteration 266\n",
      "Iteration 267\n",
      "Iteration 268\n",
      "Iteration 269\n",
      "Iteration 270\n",
      "Loss=0.3428085446357727\n",
      "Iteration 271\n",
      "Iteration 272\n",
      "Iteration 273\n",
      "Iteration 274\n",
      "Iteration 275\n",
      "Iteration 276\n",
      "Iteration 277\n",
      "Iteration 278\n",
      "Iteration 279\n",
      "Iteration 280\n",
      "Loss=0.3425792455673218\n",
      "Iteration 281\n",
      "Iteration 282\n",
      "Iteration 283\n",
      "Iteration 284\n",
      "Iteration 285\n",
      "Iteration 286\n",
      "Iteration 287\n",
      "Iteration 288\n",
      "Iteration 289\n",
      "Iteration 290\n",
      "Loss=0.34260520339012146\n",
      "Iteration 291\n",
      "Iteration 292\n",
      "Iteration 293\n",
      "Iteration 294\n",
      "Iteration 295\n",
      "Iteration 296\n",
      "Iteration 297\n",
      "Iteration 298\n",
      "Iteration 299\n",
      "Iteration 300\n",
      "Loss=0.3348866105079651\n",
      "Iteration 301\n",
      "Iteration 302\n",
      "Iteration 303\n",
      "Iteration 304\n",
      "Iteration 305\n",
      "Iteration 306\n",
      "Iteration 307\n",
      "Iteration 308\n",
      "Iteration 309\n",
      "Iteration 310\n",
      "Loss=0.3327639400959015\n",
      "Iteration 311\n",
      "Iteration 312\n",
      "Iteration 313\n",
      "Iteration 314\n",
      "Iteration 315\n",
      "Iteration 316\n",
      "Iteration 317\n",
      "Iteration 318\n",
      "Iteration 319\n",
      "Iteration 320\n",
      "Loss=0.3332229554653168\n",
      "Iteration 321\n",
      "Iteration 322\n",
      "Iteration 323\n",
      "Iteration 324\n",
      "Iteration 325\n",
      "Iteration 326\n",
      "Iteration 327\n",
      "Iteration 328\n",
      "Iteration 329\n",
      "Iteration 330\n",
      "Loss=0.33374232053756714\n",
      "Iteration 331\n",
      "Iteration 332\n",
      "Iteration 333\n",
      "Iteration 334\n",
      "Iteration 335\n",
      "Iteration 336\n",
      "Iteration 337\n",
      "Iteration 338\n",
      "Iteration 339\n",
      "Iteration 340\n",
      "Loss=0.3246473968029022\n",
      "Iteration 341\n",
      "Iteration 342\n",
      "Iteration 343\n",
      "Iteration 344\n",
      "Iteration 345\n",
      "Iteration 346\n",
      "Iteration 347\n",
      "Iteration 348\n",
      "Iteration 349\n",
      "Iteration 350\n",
      "Loss=0.32514944672584534\n",
      "Iteration 351\n",
      "Iteration 352\n",
      "Iteration 353\n",
      "Iteration 354\n",
      "Iteration 355\n",
      "Iteration 356\n",
      "Iteration 357\n",
      "Iteration 358\n",
      "Iteration 359\n",
      "Iteration 360\n",
      "Loss=0.3271885812282562\n",
      "Iteration 361\n",
      "Iteration 362\n",
      "Iteration 363\n",
      "Iteration 364\n",
      "Iteration 365\n",
      "Iteration 366\n",
      "Iteration 367\n",
      "Iteration 368\n",
      "Iteration 369\n",
      "Iteration 370\n",
      "Loss=0.3190459609031677\n",
      "Iteration 371\n",
      "Iteration 372\n",
      "Iteration 373\n",
      "Iteration 374\n",
      "Iteration 375\n",
      "Iteration 376\n",
      "Iteration 377\n",
      "Iteration 378\n",
      "Iteration 379\n",
      "Iteration 380\n",
      "Loss=0.3163197636604309\n",
      "Iteration 381\n",
      "Iteration 382\n",
      "Iteration 383\n",
      "Iteration 384\n",
      "Iteration 385\n",
      "Iteration 386\n",
      "Iteration 387\n",
      "Iteration 388\n",
      "Iteration 389\n",
      "Iteration 390\n",
      "Loss=0.31985771656036377\n",
      "Iteration 391\n",
      "Iteration 392\n",
      "Iteration 393\n",
      "Iteration 394\n",
      "Iteration 395\n",
      "Iteration 396\n",
      "Iteration 397\n",
      "Iteration 398\n",
      "Iteration 399\n",
      "Iteration 400\n",
      "Loss=0.3146582841873169\n",
      "Iteration 401\n",
      "Iteration 402\n",
      "Iteration 403\n",
      "Iteration 404\n",
      "Iteration 405\n",
      "Iteration 406\n",
      "Iteration 407\n",
      "Iteration 408\n",
      "Iteration 409\n",
      "Iteration 410\n",
      "Loss=0.31477105617523193\n",
      "Iteration 411\n",
      "Iteration 412\n",
      "Iteration 413\n",
      "Iteration 414\n",
      "Iteration 415\n",
      "Iteration 416\n",
      "Iteration 417\n",
      "Iteration 418\n",
      "Iteration 419\n",
      "Iteration 420\n",
      "Loss=0.31471624970436096\n",
      "Iteration 421\n",
      "Iteration 422\n",
      "Iteration 423\n",
      "Iteration 424\n",
      "Iteration 425\n",
      "Iteration 426\n",
      "Iteration 427\n",
      "Iteration 428\n",
      "Iteration 429\n",
      "Iteration 430\n",
      "Loss=0.31500503420829773\n",
      "Iteration 431\n",
      "Iteration 432\n",
      "Iteration 433\n",
      "Iteration 434\n",
      "Iteration 435\n",
      "Iteration 436\n",
      "Iteration 437\n",
      "Iteration 438\n",
      "Iteration 439\n",
      "Iteration 440\n",
      "Loss=0.306218683719635\n",
      "Iteration 441\n",
      "Iteration 442\n",
      "Iteration 443\n",
      "Iteration 444\n",
      "Iteration 445\n",
      "Iteration 446\n",
      "Iteration 447\n",
      "Iteration 448\n",
      "Iteration 449\n",
      "Iteration 450\n",
      "Loss=0.32468360662460327\n",
      "Iteration 451\n",
      "Iteration 452\n",
      "Iteration 453\n",
      "Iteration 454\n",
      "Iteration 455\n",
      "Iteration 456\n",
      "Iteration 457\n",
      "Iteration 458\n",
      "Iteration 459\n",
      "Iteration 460\n",
      "Loss=0.3148965537548065\n",
      "Iteration 461\n",
      "Iteration 462\n",
      "Iteration 463\n",
      "Iteration 464\n",
      "Iteration 465\n",
      "Iteration 466\n",
      "Iteration 467\n",
      "Iteration 468\n",
      "Iteration 469\n",
      "Iteration 470\n",
      "Loss=0.3085639476776123\n",
      "Iteration 471\n",
      "Iteration 472\n",
      "Iteration 473\n",
      "Iteration 474\n",
      "Iteration 475\n",
      "Iteration 476\n",
      "Iteration 477\n",
      "Iteration 478\n",
      "Iteration 479\n",
      "Iteration 480\n",
      "Loss=0.30759283900260925\n",
      "Iteration 481\n",
      "Iteration 482\n",
      "Iteration 483\n",
      "Iteration 484\n",
      "Iteration 485\n",
      "Iteration 486\n",
      "Iteration 487\n",
      "Iteration 488\n",
      "Iteration 489\n",
      "Iteration 490\n",
      "Loss=0.3017328679561615\n",
      "Iteration 491\n",
      "Iteration 492\n",
      "Iteration 493\n",
      "Iteration 494\n",
      "Iteration 495\n",
      "Iteration 496\n",
      "Iteration 497\n",
      "Iteration 498\n",
      "Iteration 499\n",
      "Iteration 500\n",
      "Loss=0.29753491282463074\n",
      "Iteration 501\n",
      "Iteration 502\n",
      "Iteration 503\n",
      "Iteration 504\n",
      "Iteration 505\n",
      "Iteration 506\n",
      "Iteration 507\n",
      "Iteration 508\n",
      "Iteration 509\n",
      "Iteration 510\n",
      "Loss=0.3303969204425812\n",
      "Iteration 511\n",
      "Iteration 512\n",
      "Iteration 513\n",
      "Iteration 514\n",
      "Iteration 515\n",
      "Iteration 516\n",
      "Iteration 517\n",
      "Iteration 518\n",
      "Iteration 519\n",
      "Iteration 520\n",
      "Loss=0.49951669573783875\n",
      "Iteration 521\n",
      "Iteration 522\n",
      "Iteration 523\n",
      "Iteration 524\n",
      "Iteration 525\n",
      "Iteration 526\n",
      "Iteration 527\n",
      "Iteration 528\n",
      "Iteration 529\n",
      "Iteration 530\n",
      "Loss=0.3803926408290863\n",
      "Iteration 531\n",
      "Iteration 532\n",
      "Iteration 533\n",
      "Iteration 534\n",
      "Iteration 535\n",
      "Iteration 536\n",
      "Iteration 537\n",
      "Iteration 538\n",
      "Iteration 539\n",
      "Iteration 540\n",
      "Loss=0.3640999495983124\n",
      "Iteration 541\n",
      "Iteration 542\n",
      "Iteration 543\n",
      "Iteration 544\n",
      "Iteration 545\n",
      "Iteration 546\n",
      "Iteration 547\n",
      "Iteration 548\n",
      "Iteration 549\n",
      "Iteration 550\n",
      "Loss=0.34296301007270813\n",
      "Iteration 551\n",
      "Iteration 552\n",
      "Iteration 553\n",
      "Iteration 554\n",
      "Iteration 555\n",
      "Iteration 556\n",
      "Iteration 557\n",
      "Iteration 558\n",
      "Iteration 559\n",
      "Iteration 560\n",
      "Loss=0.33142581582069397\n",
      "Iteration 561\n",
      "Iteration 562\n",
      "Iteration 563\n",
      "Iteration 564\n",
      "Iteration 565\n",
      "Iteration 566\n",
      "Iteration 567\n",
      "Iteration 568\n",
      "Iteration 569\n",
      "Iteration 570\n",
      "Loss=0.31995099782943726\n",
      "Iteration 571\n",
      "Iteration 572\n",
      "Iteration 573\n",
      "Iteration 574\n",
      "Iteration 575\n",
      "Iteration 576\n",
      "Iteration 577\n",
      "Iteration 578\n",
      "Iteration 579\n",
      "Iteration 580\n",
      "Loss=0.3131031394004822\n",
      "Iteration 581\n",
      "Iteration 582\n",
      "Iteration 583\n",
      "Iteration 584\n",
      "Iteration 585\n",
      "Iteration 586\n",
      "Iteration 587\n",
      "Iteration 588\n",
      "Iteration 589\n",
      "Iteration 590\n",
      "Loss=0.30738258361816406\n",
      "Iteration 591\n",
      "Iteration 592\n",
      "Iteration 593\n",
      "Iteration 594\n",
      "Iteration 595\n",
      "Iteration 596\n",
      "Iteration 597\n",
      "Iteration 598\n",
      "Iteration 599\n",
      "Iteration 600\n",
      "Loss=0.32264578342437744\n",
      "Iteration 601\n",
      "Iteration 602\n",
      "Iteration 603\n",
      "Iteration 604\n",
      "Iteration 605\n",
      "Iteration 606\n",
      "Iteration 607\n",
      "Iteration 608\n",
      "Iteration 609\n",
      "Iteration 610\n",
      "Loss=0.3027108311653137\n",
      "Iteration 611\n",
      "Iteration 612\n",
      "Iteration 613\n",
      "Iteration 614\n",
      "Iteration 615\n",
      "Iteration 616\n",
      "Iteration 617\n",
      "Iteration 618\n",
      "Iteration 619\n",
      "Iteration 620\n",
      "Loss=0.2950570583343506\n",
      "Iteration 621\n",
      "Iteration 622\n",
      "Iteration 623\n",
      "Iteration 624\n",
      "Iteration 625\n",
      "Iteration 626\n",
      "Iteration 627\n",
      "Iteration 628\n",
      "Iteration 629\n",
      "Iteration 630\n",
      "Loss=0.29195481538772583\n",
      "Iteration 631\n",
      "Iteration 632\n",
      "Iteration 633\n",
      "Iteration 634\n",
      "Iteration 635\n",
      "Iteration 636\n",
      "Iteration 637\n",
      "Iteration 638\n",
      "Iteration 639\n",
      "Iteration 640\n",
      "Loss=0.2888486385345459\n",
      "Iteration 641\n",
      "Iteration 642\n",
      "Iteration 643\n",
      "Iteration 644\n",
      "Iteration 645\n",
      "Iteration 646\n",
      "Iteration 647\n",
      "Iteration 648\n",
      "Iteration 649\n",
      "Iteration 650\n",
      "Loss=0.2861192226409912\n",
      "Iteration 651\n",
      "Iteration 652\n",
      "Iteration 653\n",
      "Iteration 654\n",
      "Iteration 655\n",
      "Iteration 656\n",
      "Iteration 657\n",
      "Iteration 658\n",
      "Iteration 659\n",
      "Iteration 660\n",
      "Loss=0.2848789691925049\n",
      "Iteration 661\n",
      "Iteration 662\n",
      "Iteration 663\n",
      "Iteration 664\n",
      "Iteration 665\n",
      "Iteration 666\n",
      "Iteration 667\n",
      "Iteration 668\n",
      "Iteration 669\n",
      "Iteration 670\n",
      "Loss=0.28225159645080566\n",
      "Iteration 671\n",
      "Iteration 672\n",
      "Iteration 673\n",
      "Iteration 674\n",
      "Iteration 675\n",
      "Iteration 676\n",
      "Iteration 677\n",
      "Iteration 678\n",
      "Iteration 679\n",
      "Iteration 680\n",
      "Loss=0.2850094437599182\n",
      "Iteration 681\n",
      "Iteration 682\n",
      "Iteration 683\n",
      "Iteration 684\n",
      "Iteration 685\n",
      "Iteration 686\n",
      "Iteration 687\n",
      "Iteration 688\n",
      "Iteration 689\n",
      "Iteration 690\n",
      "Loss=0.2818652391433716\n",
      "Iteration 691\n",
      "Iteration 692\n",
      "Iteration 693\n",
      "Iteration 694\n",
      "Iteration 695\n",
      "Iteration 696\n",
      "Iteration 697\n",
      "Iteration 698\n",
      "Iteration 699\n",
      "Iteration 700\n",
      "Loss=0.29133108258247375\n",
      "Iteration 701\n",
      "Iteration 702\n",
      "Iteration 703\n",
      "Iteration 704\n",
      "Iteration 705\n",
      "Iteration 706\n",
      "Iteration 707\n",
      "Iteration 708\n",
      "Iteration 709\n",
      "Iteration 710\n",
      "Loss=0.28121107816696167\n",
      "Iteration 711\n",
      "Iteration 712\n",
      "Iteration 713\n",
      "Iteration 714\n",
      "Iteration 715\n",
      "Iteration 716\n",
      "Iteration 717\n",
      "Iteration 718\n",
      "Iteration 719\n",
      "Iteration 720\n",
      "Loss=0.2790735960006714\n",
      "Iteration 721\n",
      "Iteration 722\n",
      "Iteration 723\n",
      "Iteration 724\n",
      "Iteration 725\n",
      "Iteration 726\n",
      "Iteration 727\n",
      "Iteration 728\n",
      "Iteration 729\n",
      "Iteration 730\n",
      "Loss=0.2747063934803009\n",
      "Iteration 731\n",
      "Iteration 732\n",
      "Iteration 733\n",
      "Iteration 734\n",
      "Iteration 735\n",
      "Iteration 736\n",
      "Iteration 737\n",
      "Iteration 738\n",
      "Iteration 739\n",
      "Iteration 740\n",
      "Loss=0.2734023928642273\n",
      "Iteration 741\n",
      "Iteration 742\n",
      "Iteration 743\n",
      "Iteration 744\n",
      "Iteration 745\n",
      "Iteration 746\n",
      "Iteration 747\n",
      "Iteration 748\n",
      "Iteration 749\n",
      "Iteration 750\n",
      "Loss=0.2724250555038452\n",
      "Iteration 751\n",
      "Iteration 752\n",
      "Iteration 753\n",
      "Iteration 754\n",
      "Iteration 755\n",
      "Iteration 756\n",
      "Iteration 757\n",
      "Iteration 758\n",
      "Iteration 759\n",
      "Iteration 760\n",
      "Loss=0.27016812562942505\n",
      "Iteration 761\n",
      "Iteration 762\n",
      "Iteration 763\n",
      "Iteration 764\n",
      "Iteration 765\n",
      "Iteration 766\n",
      "Iteration 767\n",
      "Iteration 768\n",
      "Iteration 769\n",
      "Iteration 770\n",
      "Loss=0.2836090326309204\n",
      "Iteration 771\n",
      "Iteration 772\n",
      "Iteration 773\n",
      "Iteration 774\n",
      "Iteration 775\n",
      "Iteration 776\n",
      "Iteration 777\n",
      "Iteration 778\n",
      "Iteration 779\n",
      "Iteration 780\n",
      "Loss=0.26900115609169006\n",
      "Iteration 781\n",
      "Iteration 782\n",
      "Iteration 783\n",
      "Iteration 784\n",
      "Iteration 785\n",
      "Iteration 786\n",
      "Iteration 787\n",
      "Iteration 788\n",
      "Iteration 789\n",
      "Iteration 790\n",
      "Loss=0.3076306879520416\n",
      "Iteration 791\n",
      "Iteration 792\n",
      "Iteration 793\n",
      "Iteration 794\n",
      "Iteration 795\n",
      "Iteration 796\n",
      "Iteration 797\n",
      "Iteration 798\n",
      "Iteration 799\n",
      "Iteration 800\n",
      "Loss=0.31189626455307007\n",
      "Iteration 801\n",
      "Iteration 802\n",
      "Iteration 803\n",
      "Iteration 804\n",
      "Iteration 805\n",
      "Iteration 806\n",
      "Iteration 807\n",
      "Iteration 808\n",
      "Iteration 809\n",
      "Iteration 810\n",
      "Loss=0.2876640558242798\n",
      "Iteration 811\n",
      "Iteration 812\n",
      "Iteration 813\n",
      "Iteration 814\n",
      "Iteration 815\n",
      "Iteration 816\n",
      "Iteration 817\n",
      "Iteration 818\n",
      "Iteration 819\n",
      "Iteration 820\n",
      "Loss=0.2787417471408844\n",
      "Iteration 821\n",
      "Iteration 822\n",
      "Iteration 823\n",
      "Iteration 824\n",
      "Iteration 825\n",
      "Iteration 826\n",
      "Iteration 827\n",
      "Iteration 828\n",
      "Iteration 829\n",
      "Iteration 830\n",
      "Loss=0.2698872685432434\n",
      "Iteration 831\n",
      "Iteration 832\n",
      "Iteration 833\n",
      "Iteration 834\n",
      "Iteration 835\n",
      "Iteration 836\n",
      "Iteration 837\n",
      "Iteration 838\n",
      "Iteration 839\n",
      "Iteration 840\n",
      "Loss=0.2658517062664032\n",
      "Iteration 841\n",
      "Iteration 842\n",
      "Iteration 843\n",
      "Iteration 844\n",
      "Iteration 845\n",
      "Iteration 846\n",
      "Iteration 847\n",
      "Iteration 848\n",
      "Iteration 849\n",
      "Iteration 850\n",
      "Loss=0.2628836929798126\n",
      "Iteration 851\n",
      "Iteration 852\n",
      "Iteration 853\n",
      "Iteration 854\n",
      "Iteration 855\n",
      "Iteration 856\n",
      "Iteration 857\n",
      "Iteration 858\n",
      "Iteration 859\n",
      "Iteration 860\n",
      "Loss=0.26146870851516724\n",
      "Iteration 861\n",
      "Iteration 862\n",
      "Iteration 863\n",
      "Iteration 864\n",
      "Iteration 865\n",
      "Iteration 866\n",
      "Iteration 867\n",
      "Iteration 868\n",
      "Iteration 869\n",
      "Iteration 870\n",
      "Loss=0.2602948844432831\n",
      "Iteration 871\n",
      "Iteration 872\n",
      "Iteration 873\n",
      "Iteration 874\n",
      "Iteration 875\n",
      "Iteration 876\n",
      "Iteration 877\n",
      "Iteration 878\n",
      "Iteration 879\n",
      "Iteration 880\n",
      "Loss=0.26044267416000366\n",
      "Iteration 881\n",
      "Iteration 882\n",
      "Iteration 883\n",
      "Iteration 884\n",
      "Iteration 885\n",
      "Iteration 886\n",
      "Iteration 887\n",
      "Iteration 888\n",
      "Iteration 889\n",
      "Iteration 890\n",
      "Loss=0.2597169280052185\n",
      "Iteration 891\n",
      "Iteration 892\n",
      "Iteration 893\n",
      "Iteration 894\n",
      "Iteration 895\n",
      "Iteration 896\n",
      "Iteration 897\n",
      "Iteration 898\n",
      "Iteration 899\n",
      "Iteration 900\n",
      "Loss=0.26219871640205383\n",
      "Iteration 901\n",
      "Iteration 902\n",
      "Iteration 903\n",
      "Iteration 904\n",
      "Iteration 905\n",
      "Iteration 906\n",
      "Iteration 907\n",
      "Iteration 908\n",
      "Iteration 909\n",
      "Iteration 910\n",
      "Loss=0.25619223713874817\n",
      "Iteration 911\n",
      "Iteration 912\n",
      "Iteration 913\n",
      "Iteration 914\n",
      "Iteration 915\n",
      "Iteration 916\n",
      "Iteration 917\n",
      "Iteration 918\n",
      "Iteration 919\n",
      "Iteration 920\n",
      "Loss=0.2573559582233429\n",
      "Iteration 921\n",
      "Iteration 922\n",
      "Iteration 923\n",
      "Iteration 924\n",
      "Iteration 925\n",
      "Iteration 926\n",
      "Iteration 927\n",
      "Iteration 928\n",
      "Iteration 929\n",
      "Iteration 930\n",
      "Loss=0.2589744031429291\n",
      "Iteration 931\n",
      "Iteration 932\n",
      "Iteration 933\n",
      "Iteration 934\n",
      "Iteration 935\n",
      "Iteration 936\n",
      "Iteration 937\n",
      "Iteration 938\n",
      "Iteration 939\n",
      "Iteration 940\n",
      "Loss=0.3371591866016388\n",
      "Iteration 941\n",
      "Iteration 942\n",
      "Iteration 943\n",
      "Iteration 944\n",
      "Iteration 945\n",
      "Iteration 946\n",
      "Iteration 947\n",
      "Iteration 948\n",
      "Iteration 949\n",
      "Iteration 950\n",
      "Loss=0.3042660057544708\n",
      "Iteration 951\n",
      "Iteration 952\n",
      "Iteration 953\n",
      "Iteration 954\n",
      "Iteration 955\n",
      "Iteration 956\n",
      "Iteration 957\n",
      "Iteration 958\n",
      "Iteration 959\n",
      "Iteration 960\n",
      "Loss=0.2837384343147278\n",
      "Iteration 961\n",
      "Iteration 962\n",
      "Iteration 963\n",
      "Iteration 964\n",
      "Iteration 965\n",
      "Iteration 966\n",
      "Iteration 967\n",
      "Iteration 968\n",
      "Iteration 969\n",
      "Iteration 970\n",
      "Loss=0.2697104811668396\n",
      "Iteration 971\n",
      "Iteration 972\n",
      "Iteration 973\n",
      "Iteration 974\n",
      "Iteration 975\n",
      "Iteration 976\n",
      "Iteration 977\n",
      "Iteration 978\n",
      "Iteration 979\n",
      "Iteration 980\n",
      "Loss=0.25771215558052063\n",
      "Iteration 981\n",
      "Iteration 982\n",
      "Iteration 983\n",
      "Iteration 984\n",
      "Iteration 985\n",
      "Iteration 986\n",
      "Iteration 987\n",
      "Iteration 988\n",
      "Iteration 989\n",
      "Iteration 990\n",
      "Loss=0.25408148765563965\n",
      "Iteration 991\n",
      "Iteration 992\n",
      "Iteration 993\n",
      "Iteration 994\n",
      "Iteration 995\n",
      "Iteration 996\n",
      "Iteration 997\n",
      "Iteration 998\n",
      "Iteration 999\n",
      "Iteration 1000\n",
      "Loss=0.2521993815898895\n",
      "Iteration 1001\n",
      "Iteration 1002\n",
      "Iteration 1003\n",
      "Iteration 1004\n",
      "Iteration 1005\n",
      "Iteration 1006\n",
      "Iteration 1007\n",
      "Iteration 1008\n",
      "Iteration 1009\n",
      "Iteration 1010\n",
      "Loss=0.24999994039535522\n",
      "Iteration 1011\n",
      "Iteration 1012\n",
      "Iteration 1013\n",
      "Iteration 1014\n",
      "Iteration 1015\n",
      "Iteration 1016\n",
      "Iteration 1017\n",
      "Iteration 1018\n",
      "Iteration 1019\n",
      "Iteration 1020\n",
      "Loss=0.24897103011608124\n",
      "Iteration 1021\n",
      "Iteration 1022\n",
      "Iteration 1023\n",
      "Iteration 1024\n",
      "Iteration 1025\n",
      "Iteration 1026\n",
      "Iteration 1027\n",
      "Iteration 1028\n",
      "Iteration 1029\n",
      "Iteration 1030\n",
      "Loss=0.24786393344402313\n",
      "Iteration 1031\n",
      "Iteration 1032\n",
      "Iteration 1033\n",
      "Iteration 1034\n",
      "Iteration 1035\n",
      "Iteration 1036\n",
      "Iteration 1037\n",
      "Iteration 1038\n",
      "Iteration 1039\n",
      "Iteration 1040\n",
      "Loss=0.24962975084781647\n",
      "Iteration 1041\n",
      "Iteration 1042\n",
      "Iteration 1043\n",
      "Iteration 1044\n",
      "Iteration 1045\n",
      "Iteration 1046\n",
      "Iteration 1047\n",
      "Iteration 1048\n",
      "Iteration 1049\n",
      "Iteration 1050\n",
      "Loss=0.25100916624069214\n",
      "Iteration 1051\n",
      "Iteration 1052\n",
      "Iteration 1053\n",
      "Iteration 1054\n",
      "Iteration 1055\n",
      "Iteration 1056\n",
      "Iteration 1057\n",
      "Iteration 1058\n",
      "Iteration 1059\n",
      "Iteration 1060\n",
      "Loss=0.24857769906520844\n",
      "Iteration 1061\n",
      "Iteration 1062\n",
      "Iteration 1063\n",
      "Iteration 1064\n",
      "Iteration 1065\n",
      "Iteration 1066\n",
      "Iteration 1067\n",
      "Iteration 1068\n",
      "Iteration 1069\n",
      "Iteration 1070\n",
      "Loss=0.2843324542045593\n",
      "Iteration 1071\n",
      "Iteration 1072\n",
      "Iteration 1073\n",
      "Iteration 1074\n",
      "Iteration 1075\n",
      "Iteration 1076\n",
      "Iteration 1077\n",
      "Iteration 1078\n",
      "Iteration 1079\n",
      "Iteration 1080\n",
      "Loss=0.2511577904224396\n",
      "Iteration 1081\n",
      "Iteration 1082\n",
      "Iteration 1083\n",
      "Iteration 1084\n",
      "Iteration 1085\n",
      "Iteration 1086\n",
      "Iteration 1087\n",
      "Iteration 1088\n",
      "Iteration 1089\n",
      "Iteration 1090\n",
      "Loss=0.24855782091617584\n",
      "Iteration 1091\n",
      "Iteration 1092\n",
      "Iteration 1093\n",
      "Iteration 1094\n",
      "Iteration 1095\n",
      "Iteration 1096\n",
      "Iteration 1097\n",
      "Iteration 1098\n",
      "Iteration 1099\n",
      "Iteration 1100\n",
      "Loss=0.25167152285575867\n",
      "Iteration 1101\n",
      "Iteration 1102\n",
      "Iteration 1103\n",
      "Iteration 1104\n",
      "Iteration 1105\n",
      "Iteration 1106\n",
      "Iteration 1107\n",
      "Iteration 1108\n",
      "Iteration 1109\n",
      "Iteration 1110\n",
      "Loss=0.2458430528640747\n",
      "Iteration 1111\n",
      "Iteration 1112\n",
      "Iteration 1113\n",
      "Iteration 1114\n",
      "Iteration 1115\n",
      "Iteration 1116\n",
      "Iteration 1117\n",
      "Iteration 1118\n",
      "Iteration 1119\n",
      "Iteration 1120\n",
      "Loss=0.247982919216156\n",
      "Iteration 1121\n",
      "Iteration 1122\n",
      "Iteration 1123\n",
      "Iteration 1124\n",
      "Iteration 1125\n",
      "Iteration 1126\n",
      "Iteration 1127\n",
      "Iteration 1128\n",
      "Iteration 1129\n",
      "Iteration 1130\n",
      "Loss=0.24424271285533905\n",
      "Iteration 1131\n",
      "Iteration 1132\n",
      "Iteration 1133\n",
      "Iteration 1134\n",
      "Iteration 1135\n",
      "Iteration 1136\n",
      "Iteration 1137\n",
      "Iteration 1138\n",
      "Iteration 1139\n",
      "Iteration 1140\n",
      "Loss=0.24088479578495026\n",
      "Iteration 1141\n",
      "Iteration 1142\n",
      "Iteration 1143\n",
      "Iteration 1144\n",
      "Iteration 1145\n",
      "Iteration 1146\n",
      "Iteration 1147\n",
      "Iteration 1148\n",
      "Iteration 1149\n",
      "Iteration 1150\n",
      "Loss=0.25716403126716614\n",
      "Iteration 1151\n",
      "Iteration 1152\n",
      "Iteration 1153\n",
      "Iteration 1154\n",
      "Iteration 1155\n",
      "Iteration 1156\n",
      "Iteration 1157\n",
      "Iteration 1158\n",
      "Iteration 1159\n",
      "Iteration 1160\n",
      "Loss=0.2416578084230423\n",
      "Iteration 1161\n",
      "Iteration 1162\n",
      "Iteration 1163\n",
      "Iteration 1164\n",
      "Iteration 1165\n",
      "Iteration 1166\n",
      "Iteration 1167\n",
      "Iteration 1168\n",
      "Iteration 1169\n",
      "Iteration 1170\n",
      "Loss=0.24026431143283844\n",
      "Iteration 1171\n",
      "Iteration 1172\n",
      "Iteration 1173\n",
      "Iteration 1174\n",
      "Iteration 1175\n",
      "Iteration 1176\n",
      "Iteration 1177\n",
      "Iteration 1178\n",
      "Iteration 1179\n",
      "Iteration 1180\n",
      "Loss=0.23878607153892517\n",
      "Iteration 1181\n",
      "Iteration 1182\n",
      "Iteration 1183\n",
      "Iteration 1184\n",
      "Iteration 1185\n",
      "Iteration 1186\n",
      "Iteration 1187\n",
      "Iteration 1188\n",
      "Iteration 1189\n",
      "Iteration 1190\n",
      "Loss=0.23821094632148743\n",
      "Iteration 1191\n",
      "Iteration 1192\n",
      "Iteration 1193\n",
      "Iteration 1194\n",
      "Iteration 1195\n",
      "Iteration 1196\n",
      "Iteration 1197\n",
      "Iteration 1198\n",
      "Iteration 1199\n",
      "Iteration 1200\n",
      "Loss=0.2359393686056137\n",
      "Iteration 1201\n",
      "Iteration 1202\n",
      "Iteration 1203\n",
      "Iteration 1204\n",
      "Iteration 1205\n",
      "Iteration 1206\n",
      "Iteration 1207\n",
      "Iteration 1208\n",
      "Iteration 1209\n",
      "Iteration 1210\n",
      "Loss=0.2355707734823227\n",
      "Iteration 1211\n",
      "Iteration 1212\n",
      "Iteration 1213\n",
      "Iteration 1214\n",
      "Iteration 1215\n",
      "Iteration 1216\n",
      "Iteration 1217\n",
      "Iteration 1218\n",
      "Iteration 1219\n",
      "Iteration 1220\n",
      "Loss=0.23439134657382965\n",
      "Iteration 1221\n",
      "Iteration 1222\n",
      "Iteration 1223\n",
      "Iteration 1224\n",
      "Iteration 1225\n",
      "Iteration 1226\n",
      "Iteration 1227\n",
      "Iteration 1228\n",
      "Iteration 1229\n",
      "Iteration 1230\n",
      "Loss=0.2337462306022644\n",
      "Iteration 1231\n",
      "Iteration 1232\n",
      "Iteration 1233\n",
      "Iteration 1234\n",
      "Iteration 1235\n",
      "Iteration 1236\n",
      "Iteration 1237\n",
      "Iteration 1238\n",
      "Iteration 1239\n",
      "Iteration 1240\n",
      "Loss=0.2338622361421585\n",
      "Iteration 1241\n",
      "Iteration 1242\n",
      "Iteration 1243\n",
      "Iteration 1244\n",
      "Iteration 1245\n",
      "Iteration 1246\n",
      "Iteration 1247\n",
      "Iteration 1248\n",
      "Iteration 1249\n",
      "Iteration 1250\n",
      "Loss=0.23411354422569275\n",
      "Iteration 1251\n",
      "Iteration 1252\n",
      "Iteration 1253\n",
      "Iteration 1254\n",
      "Iteration 1255\n",
      "Iteration 1256\n",
      "Iteration 1257\n",
      "Iteration 1258\n",
      "Iteration 1259\n",
      "Iteration 1260\n",
      "Loss=0.2337622195482254\n",
      "Iteration 1261\n",
      "Iteration 1262\n",
      "Iteration 1263\n",
      "Iteration 1264\n",
      "Iteration 1265\n",
      "Iteration 1266\n",
      "Iteration 1267\n",
      "Iteration 1268\n",
      "Iteration 1269\n",
      "Iteration 1270\n",
      "Loss=0.23425981402397156\n",
      "Iteration 1271\n",
      "Iteration 1272\n",
      "Iteration 1273\n",
      "Iteration 1274\n",
      "Iteration 1275\n",
      "Iteration 1276\n",
      "Iteration 1277\n",
      "Iteration 1278\n",
      "Iteration 1279\n",
      "Iteration 1280\n",
      "Loss=0.23597031831741333\n",
      "Iteration 1281\n",
      "Iteration 1282\n",
      "Iteration 1283\n",
      "Iteration 1284\n",
      "Iteration 1285\n",
      "Iteration 1286\n",
      "Iteration 1287\n",
      "Iteration 1288\n",
      "Iteration 1289\n",
      "Iteration 1290\n",
      "Loss=0.23173053562641144\n",
      "Iteration 1291\n",
      "Iteration 1292\n",
      "Iteration 1293\n",
      "Iteration 1294\n",
      "Iteration 1295\n",
      "Iteration 1296\n",
      "Iteration 1297\n",
      "Iteration 1298\n",
      "Iteration 1299\n",
      "Iteration 1300\n",
      "Loss=0.23355627059936523\n",
      "Iteration 1301\n",
      "Iteration 1302\n",
      "Iteration 1303\n",
      "Iteration 1304\n",
      "Iteration 1305\n",
      "Iteration 1306\n",
      "Iteration 1307\n",
      "Iteration 1308\n",
      "Iteration 1309\n",
      "Iteration 1310\n",
      "Loss=0.2299056053161621\n",
      "Iteration 1311\n",
      "Iteration 1312\n",
      "Iteration 1313\n",
      "Iteration 1314\n",
      "Iteration 1315\n",
      "Iteration 1316\n",
      "Iteration 1317\n",
      "Iteration 1318\n",
      "Iteration 1319\n",
      "Iteration 1320\n",
      "Loss=0.23426514863967896\n",
      "Iteration 1321\n",
      "Iteration 1322\n",
      "Iteration 1323\n",
      "Iteration 1324\n",
      "Iteration 1325\n",
      "Iteration 1326\n",
      "Iteration 1327\n",
      "Iteration 1328\n",
      "Iteration 1329\n",
      "Iteration 1330\n",
      "Loss=0.3561219573020935\n",
      "Iteration 1331\n",
      "Iteration 1332\n",
      "Iteration 1333\n",
      "Iteration 1334\n",
      "Iteration 1335\n",
      "Iteration 1336\n",
      "Iteration 1337\n",
      "Iteration 1338\n",
      "Iteration 1339\n",
      "Iteration 1340\n",
      "Loss=1.3838099241256714\n",
      "Iteration 1341\n",
      "Iteration 1342\n",
      "Iteration 1343\n",
      "Iteration 1344\n",
      "Iteration 1345\n",
      "Iteration 1346\n",
      "Iteration 1347\n",
      "Iteration 1348\n",
      "Iteration 1349\n",
      "Iteration 1350\n",
      "Loss=0.9072118401527405\n",
      "Iteration 1351\n",
      "Iteration 1352\n",
      "Iteration 1353\n",
      "Iteration 1354\n",
      "Iteration 1355\n",
      "Iteration 1356\n",
      "Iteration 1357\n",
      "Iteration 1358\n",
      "Iteration 1359\n",
      "Iteration 1360\n",
      "Loss=0.6516894698143005\n",
      "Iteration 1361\n",
      "Iteration 1362\n",
      "Iteration 1363\n",
      "Iteration 1364\n",
      "Iteration 1365\n",
      "Iteration 1366\n",
      "Iteration 1367\n",
      "Iteration 1368\n",
      "Iteration 1369\n",
      "Iteration 1370\n",
      "Loss=0.5425463318824768\n",
      "Iteration 1371\n",
      "Iteration 1372\n",
      "Iteration 1373\n",
      "Iteration 1374\n",
      "Iteration 1375\n",
      "Iteration 1376\n",
      "Iteration 1377\n",
      "Iteration 1378\n",
      "Iteration 1379\n",
      "Iteration 1380\n",
      "Loss=0.4874163568019867\n",
      "Iteration 1381\n",
      "Iteration 1382\n",
      "Iteration 1383\n",
      "Iteration 1384\n",
      "Iteration 1385\n",
      "Iteration 1386\n",
      "Iteration 1387\n",
      "Iteration 1388\n",
      "Iteration 1389\n",
      "Iteration 1390\n",
      "Loss=0.4431878328323364\n",
      "Iteration 1391\n",
      "Iteration 1392\n",
      "Iteration 1393\n",
      "Iteration 1394\n",
      "Iteration 1395\n",
      "Iteration 1396\n",
      "Iteration 1397\n",
      "Iteration 1398\n",
      "Iteration 1399\n",
      "Iteration 1400\n",
      "Loss=0.41689300537109375\n",
      "Iteration 1401\n",
      "Iteration 1402\n",
      "Iteration 1403\n",
      "Iteration 1404\n",
      "Iteration 1405\n",
      "Iteration 1406\n",
      "Iteration 1407\n",
      "Iteration 1408\n",
      "Iteration 1409\n",
      "Iteration 1410\n",
      "Loss=0.40022772550582886\n",
      "Iteration 1411\n",
      "Iteration 1412\n",
      "Iteration 1413\n",
      "Iteration 1414\n",
      "Iteration 1415\n",
      "Iteration 1416\n",
      "Iteration 1417\n",
      "Iteration 1418\n",
      "Iteration 1419\n",
      "Iteration 1420\n",
      "Loss=0.3886563777923584\n",
      "Iteration 1421\n",
      "Iteration 1422\n",
      "Iteration 1423\n",
      "Iteration 1424\n",
      "Iteration 1425\n",
      "Iteration 1426\n",
      "Iteration 1427\n",
      "Iteration 1428\n",
      "Iteration 1429\n",
      "Iteration 1430\n",
      "Loss=0.3797239661216736\n",
      "Iteration 1431\n",
      "Iteration 1432\n",
      "Iteration 1433\n",
      "Iteration 1434\n",
      "Iteration 1435\n",
      "Iteration 1436\n",
      "Iteration 1437\n",
      "Iteration 1438\n",
      "Iteration 1439\n",
      "Iteration 1440\n",
      "Loss=0.3722212314605713\n",
      "Iteration 1441\n",
      "Iteration 1442\n",
      "Iteration 1443\n",
      "Iteration 1444\n",
      "Iteration 1445\n",
      "Iteration 1446\n",
      "Iteration 1447\n",
      "Iteration 1448\n",
      "Iteration 1449\n",
      "Iteration 1450\n",
      "Loss=0.3657326102256775\n",
      "Iteration 1451\n",
      "Iteration 1452\n",
      "Iteration 1453\n",
      "Iteration 1454\n",
      "Iteration 1455\n",
      "Iteration 1456\n",
      "Iteration 1457\n",
      "Iteration 1458\n",
      "Iteration 1459\n",
      "Iteration 1460\n",
      "Loss=0.3598994314670563\n",
      "Iteration 1461\n",
      "Iteration 1462\n",
      "Iteration 1463\n",
      "Iteration 1464\n",
      "Iteration 1465\n",
      "Iteration 1466\n",
      "Iteration 1467\n",
      "Iteration 1468\n",
      "Iteration 1469\n",
      "Iteration 1470\n",
      "Loss=0.354638934135437\n",
      "Iteration 1471\n",
      "Iteration 1472\n",
      "Iteration 1473\n",
      "Iteration 1474\n",
      "Iteration 1475\n",
      "Iteration 1476\n",
      "Iteration 1477\n",
      "Iteration 1478\n",
      "Iteration 1479\n",
      "Iteration 1480\n",
      "Loss=0.3498214781284332\n",
      "Iteration 1481\n",
      "Iteration 1482\n",
      "Iteration 1483\n",
      "Iteration 1484\n",
      "Iteration 1485\n",
      "Iteration 1486\n",
      "Iteration 1487\n",
      "Iteration 1488\n",
      "Iteration 1489\n",
      "Iteration 1490\n",
      "Loss=0.3452940285205841\n",
      "Iteration 1491\n",
      "Iteration 1492\n",
      "Iteration 1493\n",
      "Iteration 1494\n",
      "Iteration 1495\n",
      "Iteration 1496\n",
      "Iteration 1497\n",
      "Iteration 1498\n",
      "Iteration 1499\n",
      "Iteration 1500\n",
      "Loss=0.34106582403182983\n",
      "Iteration 1501\n",
      "Iteration 1502\n",
      "Iteration 1503\n",
      "Iteration 1504\n",
      "Iteration 1505\n",
      "Iteration 1506\n",
      "Iteration 1507\n",
      "Iteration 1508\n",
      "Iteration 1509\n",
      "Iteration 1510\n",
      "Loss=0.33715909719467163\n",
      "Iteration 1511\n",
      "Iteration 1512\n",
      "Iteration 1513\n",
      "Iteration 1514\n",
      "Iteration 1515\n",
      "Iteration 1516\n",
      "Iteration 1517\n",
      "Iteration 1518\n",
      "Iteration 1519\n",
      "Iteration 1520\n",
      "Loss=0.3335602879524231\n",
      "Iteration 1521\n",
      "Iteration 1522\n",
      "Iteration 1523\n",
      "Iteration 1524\n",
      "Iteration 1525\n",
      "Iteration 1526\n",
      "Iteration 1527\n",
      "Iteration 1528\n",
      "Iteration 1529\n",
      "Iteration 1530\n",
      "Loss=0.33026769757270813\n",
      "Iteration 1531\n",
      "Iteration 1532\n",
      "Iteration 1533\n",
      "Iteration 1534\n",
      "Iteration 1535\n",
      "Iteration 1536\n",
      "Iteration 1537\n",
      "Iteration 1538\n",
      "Iteration 1539\n",
      "Iteration 1540\n",
      "Loss=0.3271954357624054\n",
      "Iteration 1541\n",
      "Iteration 1542\n",
      "Iteration 1543\n",
      "Iteration 1544\n",
      "Iteration 1545\n",
      "Iteration 1546\n",
      "Iteration 1547\n",
      "Iteration 1548\n",
      "Iteration 1549\n",
      "Iteration 1550\n",
      "Loss=0.3242656886577606\n",
      "Iteration 1551\n",
      "Iteration 1552\n",
      "Iteration 1553\n",
      "Iteration 1554\n",
      "Iteration 1555\n",
      "Iteration 1556\n",
      "Iteration 1557\n",
      "Iteration 1558\n",
      "Iteration 1559\n",
      "Iteration 1560\n",
      "Loss=0.32150349020957947\n",
      "Iteration 1561\n",
      "Iteration 1562\n",
      "Iteration 1563\n",
      "Iteration 1564\n",
      "Iteration 1565\n",
      "Iteration 1566\n",
      "Iteration 1567\n",
      "Iteration 1568\n",
      "Iteration 1569\n",
      "Iteration 1570\n",
      "Loss=0.3189033269882202\n",
      "Iteration 1571\n",
      "Iteration 1572\n",
      "Iteration 1573\n",
      "Iteration 1574\n",
      "Iteration 1575\n",
      "Iteration 1576\n",
      "Iteration 1577\n",
      "Iteration 1578\n",
      "Iteration 1579\n",
      "Iteration 1580\n",
      "Loss=0.31644606590270996\n",
      "Iteration 1581\n",
      "Iteration 1582\n",
      "Iteration 1583\n",
      "Iteration 1584\n",
      "Iteration 1585\n",
      "Iteration 1586\n",
      "Iteration 1587\n",
      "Iteration 1588\n",
      "Iteration 1589\n",
      "Iteration 1590\n",
      "Loss=0.31407269835472107\n",
      "Iteration 1591\n",
      "Iteration 1592\n",
      "Iteration 1593\n",
      "Iteration 1594\n",
      "Iteration 1595\n",
      "Iteration 1596\n",
      "Iteration 1597\n",
      "Iteration 1598\n",
      "Iteration 1599\n",
      "Iteration 1600\n",
      "Loss=0.31179550290107727\n",
      "Iteration 1601\n",
      "Iteration 1602\n",
      "Iteration 1603\n",
      "Iteration 1604\n",
      "Iteration 1605\n",
      "Iteration 1606\n",
      "Iteration 1607\n",
      "Iteration 1608\n",
      "Iteration 1609\n",
      "Iteration 1610\n",
      "Loss=0.3095896542072296\n",
      "Iteration 1611\n",
      "Iteration 1612\n",
      "Iteration 1613\n",
      "Iteration 1614\n",
      "Iteration 1615\n",
      "Iteration 1616\n",
      "Iteration 1617\n",
      "Iteration 1618\n",
      "Iteration 1619\n",
      "Iteration 1620\n",
      "Loss=0.3074653148651123\n",
      "Iteration 1621\n",
      "Iteration 1622\n",
      "Iteration 1623\n",
      "Iteration 1624\n",
      "Iteration 1625\n",
      "Iteration 1626\n",
      "Iteration 1627\n",
      "Iteration 1628\n",
      "Iteration 1629\n",
      "Iteration 1630\n",
      "Loss=0.3054242432117462\n",
      "Iteration 1631\n",
      "Iteration 1632\n",
      "Iteration 1633\n",
      "Iteration 1634\n",
      "Iteration 1635\n",
      "Iteration 1636\n",
      "Iteration 1637\n",
      "Iteration 1638\n",
      "Iteration 1639\n",
      "Iteration 1640\n",
      "Loss=0.3034844994544983\n",
      "Iteration 1641\n",
      "Iteration 1642\n",
      "Iteration 1643\n",
      "Iteration 1644\n",
      "Iteration 1645\n",
      "Iteration 1646\n",
      "Iteration 1647\n",
      "Iteration 1648\n",
      "Iteration 1649\n",
      "Iteration 1650\n",
      "Loss=0.301616907119751\n",
      "Iteration 1651\n",
      "Iteration 1652\n",
      "Iteration 1653\n",
      "Iteration 1654\n",
      "Iteration 1655\n",
      "Iteration 1656\n",
      "Iteration 1657\n",
      "Iteration 1658\n",
      "Iteration 1659\n",
      "Iteration 1660\n",
      "Loss=0.2998262643814087\n",
      "Iteration 1661\n",
      "Iteration 1662\n",
      "Iteration 1663\n",
      "Iteration 1664\n",
      "Iteration 1665\n",
      "Iteration 1666\n",
      "Iteration 1667\n",
      "Iteration 1668\n",
      "Iteration 1669\n",
      "Iteration 1670\n",
      "Loss=0.2980939447879791\n",
      "Iteration 1671\n",
      "Iteration 1672\n",
      "Iteration 1673\n",
      "Iteration 1674\n",
      "Iteration 1675\n",
      "Iteration 1676\n",
      "Iteration 1677\n",
      "Iteration 1678\n",
      "Iteration 1679\n",
      "Iteration 1680\n",
      "Loss=0.29644575715065\n",
      "Iteration 1681\n",
      "Iteration 1682\n",
      "Iteration 1683\n",
      "Iteration 1684\n",
      "Iteration 1685\n",
      "Iteration 1686\n",
      "Iteration 1687\n",
      "Iteration 1688\n",
      "Iteration 1689\n",
      "Iteration 1690\n",
      "Loss=0.2948800027370453\n",
      "Iteration 1691\n",
      "Iteration 1692\n",
      "Iteration 1693\n",
      "Iteration 1694\n",
      "Iteration 1695\n",
      "Iteration 1696\n",
      "Iteration 1697\n",
      "Iteration 1698\n",
      "Iteration 1699\n",
      "Iteration 1700\n",
      "Loss=0.29338788986206055\n",
      "Iteration 1701\n",
      "Iteration 1702\n",
      "Iteration 1703\n",
      "Iteration 1704\n",
      "Iteration 1705\n",
      "Iteration 1706\n",
      "Iteration 1707\n",
      "Iteration 1708\n",
      "Iteration 1709\n",
      "Iteration 1710\n",
      "Loss=0.29195430874824524\n",
      "Iteration 1711\n",
      "Iteration 1712\n",
      "Iteration 1713\n",
      "Iteration 1714\n",
      "Iteration 1715\n",
      "Iteration 1716\n",
      "Iteration 1717\n",
      "Iteration 1718\n",
      "Iteration 1719\n",
      "Iteration 1720\n",
      "Loss=0.2905809283256531\n",
      "Iteration 1721\n",
      "Iteration 1722\n",
      "Iteration 1723\n",
      "Iteration 1724\n",
      "Iteration 1725\n",
      "Iteration 1726\n",
      "Iteration 1727\n",
      "Iteration 1728\n",
      "Iteration 1729\n",
      "Iteration 1730\n",
      "Loss=0.2892657518386841\n",
      "Iteration 1731\n",
      "Iteration 1732\n",
      "Iteration 1733\n",
      "Iteration 1734\n",
      "Iteration 1735\n",
      "Iteration 1736\n",
      "Iteration 1737\n",
      "Iteration 1738\n",
      "Iteration 1739\n",
      "Iteration 1740\n",
      "Loss=0.28799760341644287\n",
      "Iteration 1741\n",
      "Iteration 1742\n",
      "Iteration 1743\n",
      "Iteration 1744\n",
      "Iteration 1745\n",
      "Iteration 1746\n",
      "Iteration 1747\n",
      "Iteration 1748\n",
      "Iteration 1749\n",
      "Iteration 1750\n",
      "Loss=0.2867639362812042\n",
      "Iteration 1751\n",
      "Iteration 1752\n",
      "Iteration 1753\n",
      "Iteration 1754\n",
      "Iteration 1755\n",
      "Iteration 1756\n",
      "Iteration 1757\n",
      "Iteration 1758\n",
      "Iteration 1759\n",
      "Iteration 1760\n",
      "Loss=0.2855682373046875\n",
      "Iteration 1761\n",
      "Iteration 1762\n",
      "Iteration 1763\n",
      "Iteration 1764\n",
      "Iteration 1765\n",
      "Iteration 1766\n",
      "Iteration 1767\n",
      "Iteration 1768\n",
      "Iteration 1769\n",
      "Iteration 1770\n",
      "Loss=0.2844085991382599\n",
      "Iteration 1771\n",
      "Iteration 1772\n",
      "Iteration 1773\n",
      "Iteration 1774\n",
      "Iteration 1775\n",
      "Iteration 1776\n",
      "Iteration 1777\n",
      "Iteration 1778\n",
      "Iteration 1779\n",
      "Iteration 1780\n",
      "Loss=0.2832839787006378\n",
      "Iteration 1781\n",
      "Iteration 1782\n",
      "Iteration 1783\n",
      "Iteration 1784\n",
      "Iteration 1785\n",
      "Iteration 1786\n",
      "Iteration 1787\n",
      "Iteration 1788\n",
      "Iteration 1789\n",
      "Iteration 1790\n",
      "Loss=0.28218385577201843\n",
      "Iteration 1791\n",
      "Iteration 1792\n",
      "Iteration 1793\n",
      "Iteration 1794\n",
      "Iteration 1795\n",
      "Iteration 1796\n",
      "Iteration 1797\n",
      "Iteration 1798\n",
      "Iteration 1799\n",
      "Iteration 1800\n",
      "Loss=0.28111258149147034\n",
      "Iteration 1801\n",
      "Iteration 1802\n",
      "Iteration 1803\n",
      "Iteration 1804\n",
      "Iteration 1805\n",
      "Iteration 1806\n",
      "Iteration 1807\n",
      "Iteration 1808\n",
      "Iteration 1809\n",
      "Iteration 1810\n",
      "Loss=0.28006303310394287\n",
      "Iteration 1811\n",
      "Iteration 1812\n",
      "Iteration 1813\n",
      "Iteration 1814\n",
      "Iteration 1815\n",
      "Iteration 1816\n",
      "Iteration 1817\n",
      "Iteration 1818\n",
      "Iteration 1819\n",
      "Iteration 1820\n",
      "Loss=0.279045045375824\n",
      "Iteration 1821\n",
      "Iteration 1822\n",
      "Iteration 1823\n",
      "Iteration 1824\n",
      "Iteration 1825\n",
      "Iteration 1826\n",
      "Iteration 1827\n",
      "Iteration 1828\n",
      "Iteration 1829\n",
      "Iteration 1830\n",
      "Loss=0.2780574560165405\n",
      "Iteration 1831\n",
      "Iteration 1832\n",
      "Iteration 1833\n",
      "Iteration 1834\n",
      "Iteration 1835\n",
      "Iteration 1836\n",
      "Iteration 1837\n",
      "Iteration 1838\n",
      "Iteration 1839\n",
      "Iteration 1840\n",
      "Loss=0.2771141827106476\n",
      "Iteration 1841\n",
      "Iteration 1842\n",
      "Iteration 1843\n",
      "Iteration 1844\n",
      "Iteration 1845\n",
      "Iteration 1846\n",
      "Iteration 1847\n",
      "Iteration 1848\n",
      "Iteration 1849\n",
      "Iteration 1850\n",
      "Loss=0.27613919973373413\n",
      "Iteration 1851\n",
      "Iteration 1852\n",
      "Iteration 1853\n",
      "Iteration 1854\n",
      "Iteration 1855\n",
      "Iteration 1856\n",
      "Iteration 1857\n",
      "Iteration 1858\n",
      "Iteration 1859\n",
      "Iteration 1860\n",
      "Loss=0.2752530574798584\n",
      "Iteration 1861\n",
      "Iteration 1862\n",
      "Iteration 1863\n",
      "Iteration 1864\n",
      "Iteration 1865\n",
      "Iteration 1866\n",
      "Iteration 1867\n",
      "Iteration 1868\n",
      "Iteration 1869\n",
      "Iteration 1870\n",
      "Loss=0.27443593740463257\n",
      "Iteration 1871\n",
      "Iteration 1872\n",
      "Iteration 1873\n",
      "Iteration 1874\n",
      "Iteration 1875\n",
      "Iteration 1876\n",
      "Iteration 1877\n",
      "Iteration 1878\n",
      "Iteration 1879\n",
      "Iteration 1880\n",
      "Loss=0.27344465255737305\n",
      "Iteration 1881\n",
      "Iteration 1882\n",
      "Iteration 1883\n",
      "Iteration 1884\n",
      "Iteration 1885\n",
      "Iteration 1886\n",
      "Iteration 1887\n",
      "Iteration 1888\n",
      "Iteration 1889\n",
      "Iteration 1890\n",
      "Loss=0.27287551760673523\n",
      "Iteration 1891\n",
      "Iteration 1892\n",
      "Iteration 1893\n",
      "Iteration 1894\n",
      "Iteration 1895\n",
      "Iteration 1896\n",
      "Iteration 1897\n",
      "Iteration 1898\n",
      "Iteration 1899\n",
      "Iteration 1900\n",
      "Loss=0.2717389762401581\n",
      "Iteration 1901\n",
      "Iteration 1902\n",
      "Iteration 1903\n",
      "Iteration 1904\n",
      "Iteration 1905\n",
      "Iteration 1906\n",
      "Iteration 1907\n",
      "Iteration 1908\n",
      "Iteration 1909\n",
      "Iteration 1910\n",
      "Loss=0.27132850885391235\n",
      "Iteration 1911\n",
      "Iteration 1912\n",
      "Iteration 1913\n",
      "Iteration 1914\n",
      "Iteration 1915\n",
      "Iteration 1916\n",
      "Iteration 1917\n",
      "Iteration 1918\n",
      "Iteration 1919\n",
      "Iteration 1920\n",
      "Loss=0.27016907930374146\n",
      "Iteration 1921\n",
      "Iteration 1922\n",
      "Iteration 1923\n",
      "Iteration 1924\n",
      "Iteration 1925\n",
      "Iteration 1926\n",
      "Iteration 1927\n",
      "Iteration 1928\n",
      "Iteration 1929\n",
      "Iteration 1930\n",
      "Loss=0.2697846293449402\n",
      "Iteration 1931\n",
      "Iteration 1932\n",
      "Iteration 1933\n",
      "Iteration 1934\n",
      "Iteration 1935\n",
      "Iteration 1936\n",
      "Iteration 1937\n",
      "Iteration 1938\n",
      "Iteration 1939\n",
      "Iteration 1940\n",
      "Loss=0.2689801752567291\n",
      "Iteration 1941\n",
      "Iteration 1942\n",
      "Iteration 1943\n",
      "Iteration 1944\n",
      "Iteration 1945\n",
      "Iteration 1946\n",
      "Iteration 1947\n",
      "Iteration 1948\n",
      "Iteration 1949\n",
      "Iteration 1950\n",
      "Loss=0.267766535282135\n",
      "Iteration 1951\n",
      "Iteration 1952\n",
      "Iteration 1953\n",
      "Iteration 1954\n",
      "Iteration 1955\n",
      "Iteration 1956\n",
      "Iteration 1957\n",
      "Iteration 1958\n",
      "Iteration 1959\n",
      "Iteration 1960\n",
      "Loss=0.26716551184654236\n",
      "Iteration 1961\n",
      "Iteration 1962\n",
      "Iteration 1963\n",
      "Iteration 1964\n",
      "Iteration 1965\n",
      "Iteration 1966\n",
      "Iteration 1967\n",
      "Iteration 1968\n",
      "Iteration 1969\n",
      "Iteration 1970\n",
      "Loss=0.26634782552719116\n",
      "Iteration 1971\n",
      "Iteration 1972\n",
      "Iteration 1973\n",
      "Iteration 1974\n",
      "Iteration 1975\n",
      "Iteration 1976\n",
      "Iteration 1977\n",
      "Iteration 1978\n",
      "Iteration 1979\n",
      "Iteration 1980\n",
      "Loss=0.26560157537460327\n",
      "Iteration 1981\n",
      "Iteration 1982\n",
      "Iteration 1983\n",
      "Iteration 1984\n",
      "Iteration 1985\n",
      "Iteration 1986\n",
      "Iteration 1987\n",
      "Iteration 1988\n",
      "Iteration 1989\n",
      "Iteration 1990\n",
      "Loss=0.2647959589958191\n",
      "Iteration 1991\n",
      "Iteration 1992\n",
      "Iteration 1993\n",
      "Iteration 1994\n",
      "Iteration 1995\n",
      "Iteration 1996\n",
      "Iteration 1997\n",
      "Iteration 1998\n",
      "Iteration 1999\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the model\n",
    "torch.manual_seed(42)\n",
    "model=FashionClassifier(0.11,2000,38)\n",
    "model.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deaab22f-0181-4391-9418-c5257ac50646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model\n",
    "model.eval()\n",
    "y_pred=model.forward(test_x)\n",
    "y_labels=torch.argmax(y_pred,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5baa67ea-656f-442a-9540-8f122a01db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:87.29999542236328\n"
     ]
    }
   ],
   "source": [
    "#Test the accuracy\n",
    "correct=torch.sum(y_labels==test_y)\n",
    "print(f\"Accuracy:{correct/100.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ee6df-c7d3-4bd9-82f4-3187e30fd232",
   "metadata": {},
   "source": [
    "<h1> After numerous tries , i could only optimize the accuracy to 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ffcf25-c25a-4a6c-b8b1-f1f098c462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving tHe model\n",
    "torch.save(model,'FashionMnist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c4e42-3116-4049-af8a-053d5224a674",
   "metadata": {},
   "source": [
    "<h1>Now the task left is  to create a GUI for new predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ad477-9e71-4597-bfaf-fa07b5e3263b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
